{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SCRIPT DE EXECUÇÃO DO MODELO PREDITOR DO IDSUS 2010 A \n",
    "PARTIR DOS DADOS DO CENSO 2010\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTAÇÕES \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" CARREGAR A BASE\n",
    "    Escolher enter o caminho para Windows ou Linux (deixar um dos dois comentado).\n",
    "    Carrega TABELA_CENSO_IDSUS_2010.csv em base como um dataframe.\n",
    "\"\"\"\n",
    "mainFolderpath = %pwd\n",
    "\n",
    "# opção WINDOWS ---------------------------------------------------------\n",
    "caminho_idSUS_Censo2010 = mainFolderpath + \"\\\\TABELA_CENSO_IDSUS_2010.csv\"\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# # LINUX ----------------------------------------------------------------\n",
    "# caminho_idSUS_Censo2010 = mainFolderpath + \"/TABELA_CENSO_IDSUS_2010.csv\"\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "base = pd.read_csv(caminho_idSUS_Censo2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRATAMENTO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Observação --> Executar apenas as seguintes opções abaixo isoladamento:\n",
    "Opção 1, \n",
    "Opção 2,\n",
    "Opção 3,\n",
    "Opção 3 com a opção 4,\n",
    "Opção 5\n",
    "\n",
    "Escolher qual(is) caixa(s) de texto abaixo operar e \n",
    "comentar as outras (ctrl + '/' do teclado numérico) \n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# OPÇÃO 1: CASO SE DESEJE EXCLUIR TODAS AS COLUNAS QUE TENHAM ALGUM VALOR FALTANTE\n",
    "# -- Reduz o dataset de 185 var. preditoras para 61 var.\n",
    "\n",
    "# \"\"\"\n",
    "# # Exclui as colunas com valores NaN\n",
    "# base = base.dropna(axis = 1)\n",
    "\n",
    "# # INSTRUÇÕES IMPORTANTES:\n",
    "# # Utilizar '1' no @@@ para predizer o 'idsus_fx' ou\n",
    "# # '2' para predizer o 'Grupo Homogêneo'\n",
    "# # -----------------------------------------------------\n",
    "# classe = base.iloc[:, @@@].values\n",
    "# # -----------------------------------------------------\n",
    "# previsores = base.iloc[:, np.r_[3:base.shape[1]]].values\n",
    "\n",
    "# # PREVISORES: Escalonamento das variáveis\n",
    "# scaler = StandardScaler()\n",
    "# previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "# # CLASSE: Transformação de ordinal para discreta\n",
    "# labelencorder_classe = LabelEncoder()\n",
    "# classe = labelencorder_classe.fit_transform(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" \n",
    "# OPÇÃO 2: SELECIONAR AS VARIÁVEIS PREDITORES POR UM NÚMERO FIXO (K) A \n",
    "# PARTIR DO SelectKBest\n",
    "# \"\"\"\n",
    "\n",
    "# # INSTRUÇÕES IMPORTANTES:\n",
    "# # Utilizar '2' no @@@ para predizer o 'idsus_fx' ou\n",
    "# # '3' para predizer o 'Grupo Homogêneo'\n",
    "# # -----------------------------------------------------\n",
    "# classe = base.iloc[:, @@@].values\n",
    "# # -----------------------------------------------------\n",
    "# previsores = base.iloc[:, np.r_[1,4:base.shape[1]]].values\n",
    "\n",
    "# # PREVISORES: SimpleImputer\n",
    "# totalColunas = len(previsores[0])\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imputer = imputer.fit(previsores[:, 0:totalColunas])\n",
    "# previsores[:,0:totalColunas] = imputer.transform(previsores[:,0:totalColunas])\n",
    "\n",
    "# # SelectKBest\n",
    "# # INSTRUÇÕES IMPORTANTES:\n",
    "# # mudar o valor de k (atual = 60) para o número de variáveis a serem utilizadas.\n",
    "# # -----------------------------------------------------\n",
    "# previsores = SelectKBest(chi2, k=60).fit_transform(previsores, classe)\n",
    "# # -----------------------------------------------------\n",
    "\n",
    "# # PREVISORES: Escalonamento das variáveis\n",
    "# scaler = StandardScaler()\n",
    "# previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "# # CLASSE: Transformação de ordinal para discreta\n",
    "# labelencorder_classe = LabelEncoder()\n",
    "# classe = labelencorder_classe.fit_transform(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" \n",
    "# OPÇÃO 3: UTILIZA TODAS AS 185 VARIÁVEIS PREDITORAS DO DATASET\n",
    "# \"\"\"\n",
    "\n",
    "# # INSTRUÇÕES IMPORTANTES:\n",
    "# # Utilizar '2' no @@@ para predizer o 'idsus_fx' ou\n",
    "# # '3' para predizer o 'Grupo Homogêneo'\n",
    "# # -----------------------------------------------------\n",
    "# classe = base.iloc[:, @@@].values\n",
    "# # -----------------------------------------------------\n",
    "# previsores = base.iloc[:, np.r_[1,4:base.shape[1]]].values\n",
    "\n",
    "# # PREVISORES: Substituição de valores faltantes\n",
    "# totalColunas = len(previsores[0])\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imputer = imputer.fit(previsores[:, 0:totalColunas])\n",
    "# previsores[:,0:totalColunas] = imputer.transform(previsores[:,0:totalColunas])\n",
    "\n",
    "# # PREVISORES: Escalonamento das variáveis\n",
    "# scaler = StandardScaler()\n",
    "# previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "# # CLASSE: Transformação de ordinal para discreta\n",
    "# labelencorder_classe = LabelEncoder()\n",
    "# classe = labelencorder_classe.fit_transform(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"\"\" \n",
    "# OPÇÃO 4: EXECUTA FEATURE SELECTION A PARTIR DE UM PARÂMETRO DE IMPORTANCE PASSADO\n",
    "# Modificar a var parâmetroImportância abaixo para o valor desejado.\n",
    "# Valores maiores reduzirão as variáves e valores menores utilizarão mais variáveis do dataset.\n",
    "\n",
    "# OBS: EXIGE QUE A OPÇÃO 3 RODE ANTES\n",
    "# \"\"\"\n",
    "\n",
    "# # INSTRUÇÕES IMPORTANTES:\n",
    "# #Modificar conforme desejado:\n",
    "# # -----------------------------------------------------\n",
    "# parâmetroImportância = 0.015\n",
    "# # -----------------------------------------------------\n",
    "\n",
    "# selection = ExtraTreesClassifier()\n",
    "# selection.fit(previsores, classe)\n",
    "# importances = selection.feature_importances_\n",
    "\n",
    "# indexes = []\n",
    "# for i in range(len(importances)):\n",
    "#     if importances[i] > parâmetroImportância:\n",
    "#         indexes.append(i)\n",
    "\n",
    "# # Previsores passa a ter somente as features selecionadas no for anterior.\n",
    "# previsores = previsores[:, indexes]\n",
    "\n",
    "# # Plota um heatmap dos previsores (para ver correlação)\n",
    "# df_corr = pd.DataFrame(previsores).corr()\n",
    "# print('Total de variáveis utilizadas: '+len(indexes))\n",
    "# sns.heatmap(df_corr, xticklabels=df_corr.columns, yticklabels=df_corr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" \n",
    "# OPÇÃO 5: SELECIONA AS 7 VARIÁVEIS PREDITORAS MAIS REPRESENTATIVAS\n",
    "# Apenas executar, não é preciso configurar nada\n",
    "# \"\"\"\n",
    "# lista_var = np.r_[89, 113, 144, 145, 148, 149, 150]\n",
    "\n",
    "# classe = base.iloc[:, 3].values\n",
    "# previsores_df = base.iloc[:, np.r_[1,4:base.shape[1]]]\n",
    "# previsores = previsores_df.iloc[:, lista_var ].values\n",
    "\n",
    "# # PREVISORES: Substituição de valores faltantes\n",
    "# totalColunas = len(previsores[0])\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# imputer = imputer.fit(previsores[:, 0:totalColunas])\n",
    "# previsores[:,0:totalColunas] = imputer.transform(previsores[:,0:totalColunas])\n",
    "\n",
    "# # PREVISORES: Escalonamento das variáveis\n",
    "# scaler = StandardScaler()\n",
    "# previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "# # CLASSE: Transformação de ordinal para discreta\n",
    "# labelencorder_classe = LabelEncoder()\n",
    "# classe = labelencorder_classe.fit_transform(classe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ESCOLHER UM DOS DOIS ALGORITMOS ABAIXO:\n",
    " - RANDOM FOREST ou \n",
    " - EXTRA TREES \n",
    " OBS: (deixar comentado o algoritmo que não for ser usado)\n",
    "\"\"\"\n",
    "# _____________________________________________________________________________\n",
    "# RANDOM FOREST\n",
    "# modificar o valor de n_estimators para o número de árvores que se deseja criar.\n",
    "#classificador = RandomForestClassifier(n_estimators=60, criterion='entropy', random_state=0)\n",
    "# _____________________________________________________________________________\n",
    "\n",
    "# _____________________________________________________________________________\n",
    "\n",
    "# ----ExtraTrees\n",
    "classificador = ExtraTreesClassifier()\n",
    "# _____________________________________________________________________________\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ESCOLHER UM DOS MODOS DE SIMULAÇÃO ABAIXO:\n",
    " - VALIDAÇÃO CRUZADA ou\n",
    " - SEPARAÇÃO DE TRAIN/TEST\n",
    "  OBS: (deixar comentado o algoritmo que não for ser usado)\n",
    "\"\"\"\n",
    "# _____________________________________________________________________________\n",
    "# CROSS VALIDATION SCORE com 10 folds\n",
    "resultados = cross_val_score(classificador, previsores, classe, cv = 10)\n",
    "print(resultados.mean())\n",
    "print(resultados.std())\n",
    "print(resultados)\n",
    "# _____________________________________________________________________________\n",
    "\n",
    "\n",
    "# _____________________________________________________________________________\n",
    "# SEPARAÇÃO DE TREINO E TESTE\n",
    "# Modificar o parâmetro de test_size de acordo com o tamanho da teste (recomendado entre 0.2 a 0.3)\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, test_size=0.2, random_state=0)\n",
    "\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "print(precisao)\n",
    "# _____________________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
